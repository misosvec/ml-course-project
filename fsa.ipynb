{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sKPmLsa3FLQ"
      },
      "source": [
        "# ML final project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUwCQmQ03FLc"
      },
      "source": [
        "## Download dataset and libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install transformers\n",
        "!pip install xgboost\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install groq\n",
        "\n",
        "!wget -O dataset.zip \"https://www.kaggle.com/api/v1/datasets/download/sbhatti/financial-sentiment-analysis\"\n",
        "!unzip -p dataset.zip > dataset.csv"
      ],
      "metadata": {
        "id": "PSTUaB1h5Sn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "jHb4Gbwy68jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZyXZDHe06YBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset\n"
      ],
      "metadata": {
        "id": "o_7rqZYhJyvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download already created embeddings\n",
        "If you want to create the embeddings yourself, skip this cell and continue with the next cells. They will produce embeddings using the BERT-large-uncased model on a GPU."
      ],
      "metadata": {
        "id": "R0ebQlrBre19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/misosvec/ml-course-project/raw/refs/heads/main/cls_embeddings.npy\n",
        "!wget https://github.com/misosvec/ml-course-project/raw/refs/heads/main/sum_embeddings.npy\n",
        "!wget https://github.com/misosvec/ml-course-project/raw/refs/heads/main/mean_embeddings.npy\n",
        "!wget https://github.com/misosvec/ml-course-project/raw/refs/heads/main/max_embeddings.npy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "sum_embeddings = np.load('sum_embeddings.npy')\n",
        "max_embeddings = np.load('max_embeddings.npy')\n",
        "cls_embeddings = np.load('cls_embeddings.npy')\n",
        "mean_embeddings = np.load('mean_embeddings.npy')"
      ],
      "metadata": {
        "id": "B-T8cN6TqqCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Create embeddings"
      ],
      "metadata": {
        "id": "oWB_DlHBJoqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-large-cased\")\n",
        "model = AutoModel.from_pretrained(\"google-bert/bert-large-cased\")"
      ],
      "metadata": {
        "id": "smXJg-1TMHr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenize X"
      ],
      "metadata": {
        "id": "XVQ6S1qRrUQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenizer(\n",
        "    df[\"Sentence\"].tolist(),\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "BUH3W6v0pGEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate X embeddings using the BERT on GPU"
      ],
      "metadata": {
        "id": "ugJo4EAirts5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "all_sentences_embeddings = []\n",
        "\n",
        "# dataset will be moved to GPU\n",
        "input_ids = X['input_ids'].to(device)\n",
        "attention_mask = X['attention_mask'].to(device)\n",
        "dataset = TensorDataset(input_ids, attention_mask)\n",
        "\n",
        "# we are using batches due to memory capacity\n",
        "batch_size = 1024\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for batch in dataloader:\n",
        "  input_ids_batch, attention_mask_batch = batch\n",
        "  input_ids_batch = input_ids_batch.to(device)\n",
        "  attention_mask_batch = attention_mask_batch.to(device)\n",
        "  # using no_grad for another memory optimization\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
        "    all_sentences_embeddings.append(outputs.last_hidden_state)\n",
        "\n",
        "# Combine all batches\n",
        "all_sentences_embeddings = torch.cat(all_sentences_embeddings, dim=0)"
      ],
      "metadata": {
        "id": "TxFWqAGvXIHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sum_embeddings = all_sentences_embeddings.sum(dim=1)\n",
        "max_embeddings, _ = all_sentences_embeddings.max(dim=1)\n",
        "cls_embeddings = all_sentences_embeddings[:, 0, :]\n",
        "mean_embeddings = all_sentences_embeddings.mean(dim=1)\n",
        "\n",
        "# bring it back to cpu\n",
        "sum_embeddings = sum_embeddings.cpu().numpy()\n",
        "max_embeddings = max_embeddings.cpu().numpy()\n",
        "cls_embeddings = cls_embeddings.cpu().numpy()\n",
        "mean_embeddings = mean_embeddings.cpu().numpy()\n",
        "\n",
        "# np.save(\"cls_embeddings.npy\", cls_embeddings)\n",
        "# np.save(\"sum_embeddings.npy\", sum_embeddings)\n",
        "# np.save(\"max_embeddings.npy\", max_embeddings)\n",
        "# np.save(\"mean_embeddings.npy\", mean_embeddings)"
      ],
      "metadata": {
        "id": "JGSeXctLHdRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode target variable y"
      ],
      "metadata": {
        "id": "d6vaE--ZsQYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = cls_embeddings\n",
        "# X = sum_embeddings\n",
        "# X = max_embeddings\n",
        "X = mean_embeddings\n",
        "\n",
        "y = df[\"Sentiment\"].to_numpy()\n",
        "y[y == 'positive'] = 0\n",
        "y[y == 'negative'] = 1\n",
        "y[y == 'neutral'] = 2\n",
        "y = y.astype(int)"
      ],
      "metadata": {
        "id": "JT3td_93XyBw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datset train, valid, test split"
      ],
      "metadata": {
        "id": "7Qh5VSw7KDq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ~70% train (4090)\n",
        "# ~15% validation (876)\n",
        "# ~15% test (876)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=876, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=876, random_state=42)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "9odmho779-LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and validation evaluate function"
      ],
      "metadata": {
        "id": "xYcktHuRAF6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_valid_eval(model, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val):\n",
        "  print(f\"{type(model).__name__} training acccuracy: {accuracy_score(y_train, model.predict(X_train))}\")\n",
        "  print(f\"{type(model).__name__} validation accuracy: {accuracy_score(y_val, model.predict(X_val))}\")"
      ],
      "metadata": {
        "id": "9UBlrdSdCIq9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model"
      ],
      "metadata": {
        "id": "EDR_aPgwTfxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
        "baseline.fit(X_train, y_train)\n",
        "train_valid_eval(baseline)"
      ],
      "metadata": {
        "id": "UTSZZ8-ZTiBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Gradient Boosted Classifier\n",
        "Gradient boosted trees."
      ],
      "metadata": {
        "id": "kOirjPEyBhcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgbcls = XGBClassifier(\n",
        "    n_estimators=1000, # number of boosting rounds\n",
        "    max_depth=3,\n",
        "    num_class=3,\n",
        "    colsample_bytree=0.8, #subsampling 80% of columns for each tree\n",
        "    learning_rate=0.002,\n",
        "    eval_metric=[\"mlogloss\"],\n",
        "    early_stopping_rounds=12\n",
        ")\n",
        "xgbcls.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], verbose=False)\n",
        "train_valid_eval(xgbcls)"
      ],
      "metadata": {
        "id": "92WERlgsG-uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost Random Forests"
      ],
      "metadata": {
        "id": "4sCu-18ZKZ3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRFClassifier\n",
        "\n",
        "# Define the classifier\n",
        "xgbrfcls = XGBRFClassifier(\n",
        "    n_estimators=6,\n",
        "    max_depth=5,\n",
        "    num_class=3,\n",
        "    learning_rate=0.003,\n",
        "    eval_metric=[\"mlogloss\"],\n",
        ")\n",
        "\n",
        "xgbrfcls.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    verbose=1\n",
        ")\n",
        "train_valid_eval(xgbrfcls)"
      ],
      "metadata": {
        "id": "OCon1OT_JBz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-learn Random Forest"
      ],
      "metadata": {
        "id": "zgnMnOpVG8ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfcls = RandomForestClassifier(\n",
        "    n_estimators=40,\n",
        "    max_depth=6,\n",
        "    criterion=\"gini\",\n",
        "    n_jobs=-1 # paralleization\n",
        ")\n",
        "rfcls.fit(X_train, y_train)\n",
        "train_valid_eval(rfcls)"
      ],
      "metadata": {
        "id": "V9KrjGznHA67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-learn AdaBoost"
      ],
      "metadata": {
        "id": "ZEVQYSF_Wlia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "abcls = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=4),\n",
        "    n_estimators=120,\n",
        "    learning_rate=0.001\n",
        ")\n",
        "abcls.fit(X_train, y_train)\n",
        "train_valid_eval(abcls)"
      ],
      "metadata": {
        "id": "_z7-KbOtWkGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HistGadientBoostedClassifier"
      ],
      "metadata": {
        "id": "rcrQNEOomp0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgbcls = HistGradientBoostingClassifier(\n",
        "    max_iter=800,\n",
        "    max_depth=2,\n",
        "    learning_rate=0.005\n",
        ")\n",
        "hgbcls.fit(X_train, y_train)\n",
        "train_valid_eval(hgbcls)"
      ],
      "metadata": {
        "id": "moupimBOmqao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM attempt\n"
      ],
      "metadata": {
        "id": "h3gckcAD2Zmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_svm = scaler.fit_transform(X_train)\n",
        "X_val_svm = scaler.transform(X_val)\n",
        "X_test_svm = scaler.transform(X_test)\n",
        "\n",
        "svc = SVC(kernel='rbf')\n",
        "svc.fit(X_train_svm, y_train)\n",
        "train_valid_eval(svc)\n",
        "models_evaluation([svc], X=X_test_svm, y=y_test)"
      ],
      "metadata": {
        "id": "t1m51Nfz2nAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Groq LLama"
      ],
      "metadata": {
        "id": "Gos4EDhsBL9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "  api_key='TODO'\n",
        ")\n",
        "\n",
        "def generate_prompt(user_content):\n",
        "  return [\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Act as a classifier for financial sentiment analysis.\"\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Classify the following text as a 0=positive, 1=negative, or 2=neutral. Output only the single number.\\n\\nText:\" + user_content,\n",
        "      }\n",
        "  ]"
      ],
      "metadata": {
        "id": "A3znT0CSjZOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running classification using Llama model on test dataset"
      ],
      "metadata": {
        "id": "vCohiC7HIhco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('dataset.csv')\n",
        "X = df['Sentence']\n",
        "y = df[\"Sentiment\"].to_numpy()\n",
        "y[y == 'positive'] = 0\n",
        "y[y == 'negative'] = 1\n",
        "y[y == 'neutral'] = 2\n",
        "y = y.astype(int)\n",
        "\n",
        "# ~70% train (4090)\n",
        "# ~15% validation (876)\n",
        "# ~15% test (876)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=876, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=876, random_state=42)\n",
        "\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "index = 0\n",
        "\n",
        "for i, (sentence, label) in enumerate(zip(X_test, y_test)):\n",
        "  index = i\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    messages=generate_prompt(sentence),\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "  pred = chat_completion.choices[0].message.content\n",
        "\n",
        "  try:\n",
        "    pred = int(pred)\n",
        "    y_pred.append(pred)\n",
        "    y_true.append(label)\n",
        "    print(f\"Index={i} Sentence={sentence[:10]} Sentiment={label} classified as {pred}\")\n",
        "  except ValueError as e:\n",
        "    print(f\"Failed to convert to int, Index={i} Sentence={sentence[:10]} Sentiment={label} classified as {pred}\")\n",
        "    break\n",
        "  time.sleep(2)"
      ],
      "metadata": {
        "id": "b3kzPBYWIkJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Llama accuracy on testing dataset"
      ],
      "metadata": {
        "id": "FJkBt5NKcGq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Llama Accuracy: {accuracy}\")\n",
        "\n",
        "# y_true_llama = np.array(y_true, dtype=np.uint8)\n",
        "# y_pred_llama = np.array(y_pred, dtype=np.uint8)\n",
        "# np.save(\"y_true_llama.npy\", y_true_llama)\n",
        "# np.save(\"y_pred_llama.npy\", y_pred_llama)"
      ],
      "metadata": {
        "id": "OVv5lOQ4JSrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval models on test dataset"
      ],
      "metadata": {
        "id": "d1Wi2VT9kW4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def models_evaluation(models, X=X_test, y=y_test):\n",
        "  for model in models:\n",
        "    print(f\"{type(model).__name__} accuracy: {accuracy_score(y, model.predict(X))}\")\n",
        "\n",
        "models = [baseline, xgbcls, xgbrfcls, rfcls, abcls, hgbcls]\n",
        "models_evaluation(models, X=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "7A3MXJhTkZVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Results"
      ],
      "metadata": {
        "id": "iR-haCQ0iLa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.lines as mlines\n",
        "\n",
        "groups = ['Llama-3.3-70b-versatile', 'Baseline (majority)', 'XGBClassifier', 'XGBRFClassifier', 'Random Forest (sklearn)',\n",
        "         'AdaBoost with Decision Tree', 'HistGradientBoostingClassifier']\n",
        "sub_groups = ['CLS embeddings', 'Mean embeddings', 'Sum embeddings', 'Max embeddings']\n",
        "\n",
        "accuracy = [[75.11, 75.11, 75.11, 75.11],\n",
        "            [51.94, 51.94, 51.94, 51.94],\n",
        "            [66.78, 67.23, 67.23, 65.75],\n",
        "            [65.29, 65.75, 65.75, 62.32],\n",
        "            [65.63, 65.41, 66.09, 62.10],\n",
        "            [60.27, 60.84, 60.84, 60.61],\n",
        "            [69.86, 68.26, 68.26, 66.89]\n",
        "            ]\n",
        "\n",
        "accuracy = np.array(accuracy) / 100\n",
        "x = np.arange(len(groups))\n",
        "width = 0.22\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 8), dpi=300)\n",
        "colors = ['darkorange', 'royalblue', 'gold', 'fuchsia']\n",
        "\n",
        "# # Plot each sub_group as a set of bars\n",
        "# for i in range(len(sub_groups)):\n",
        "#   ax.bar(x+ i * width, accuracy[:, i], width, label=sub_groups[i], color=colors[i])\n",
        "\n",
        "for i in range(len(sub_groups)):\n",
        "    for j in range(len(groups)):\n",
        "        bar = ax.bar(x[j] + i * width, accuracy[j, i], width, color=colors[i])\n",
        "        # Add vertical percentage label inside the bar\n",
        "        if j != 0 and j != 1:\n",
        "          ax.text(x[j] + i * width, accuracy[j, i] / 2, f'{accuracy[j, i] * 100:.2f}%', ha='center', va='bottom', rotation=90, fontsize=11, color='black')\n",
        "\n",
        "# Overwrite bar for Llama\n",
        "for i in range(len(sub_groups)):\n",
        "  ax.bar(np.array([0])+ i * width, accuracy[0, i], width, label=sub_groups[i], color='cyan')\n",
        "ax.text(np.array([0]) + 1.5 * width, accuracy[0, 0] / 2, f'{accuracy[0, 0] * 100:.2f}%', ha='center', va='bottom', fontsize=11, color='black')\n",
        "\n",
        "# Overwrite bar for basline\n",
        "for i in range(len(sub_groups)):\n",
        "  ax.bar(np.array([1])+ i * width, accuracy[1, i], width, label=sub_groups[i], color='springgreen')\n",
        "ax.text(np.array([1]) + 1.5 * width, accuracy[0, 0] / 2, f'{accuracy[1, 0] * 100:.2f}%', ha='center', va='top', fontsize=11, color='black')\n",
        "\n",
        "ax.set_xlabel('Models', fontsize=11)\n",
        "ax.set_ylabel('Accuracy', fontsize=11)\n",
        "ax.set_title('Models Accuracy on Test Dataset')\n",
        "\n",
        "ax.set_xticks(np.arange(len(groups)) + width * 3.5)\n",
        "ax.set_xticklabels(groups, rotation=60, ha='right', fontsize=11)\n",
        "ax.tick_params(axis='y', labelsize=11)\n",
        "\n",
        "handles = []\n",
        "for color, label in zip(colors, sub_groups):\n",
        "  handle = mlines.Line2D([], [], marker='o', color='w', label=label, markersize=10, markerfacecolor=color)\n",
        "  handles.append(handle)\n",
        "\n",
        "ax.legend(title='Training Data Type', labels=sub_groups, handles=handles)\n",
        "\n",
        "ax.set_ylim(0, 1)\n",
        "ax.yaxis.set_major_locator(mtick.MultipleLocator(0.05))\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rGhyelv_ilQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for plotting train and validation loss"
      ],
      "metadata": {
        "id": "WOxUn4qrVS8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = xgbrfc.evals_result()\n",
        "train_results = results['validation_0']\n",
        "valid_results = results['validation_1']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(\n",
        "    range(len(train_results['mlogloss'])),\n",
        "    train_results['mlogloss'],\n",
        "    label='Training Loss (mlogloss)',\n",
        "    marker='o'\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    range(len(valid_results['mlogloss'])),\n",
        "    valid_results['mlogloss'],\n",
        "    label='Validation (mlogloss)',\n",
        "    marker='o'\n",
        ")\n",
        "\n",
        "\n",
        "plt.xlabel('Boosting rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Boosting Rounds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i-Ro0SNkznTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for plotting confusion matrix"
      ],
      "metadata": {
        "id": "eDFgsZ6jVf7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = xgbclf.predict(X_val)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix from XGBClassifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Jd5jCMXKnyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code XGBoost feature importance"
      ],
      "metadata": {
        "id": "uOEEMZPYXL_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 30))\n",
        "plot_importance(xgbclf,\n",
        "                importance_type='weight',\n",
        "                max_num_features=20,\n",
        "                height=0.5)\n",
        "plt.title(\"Top 20 Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_bU9DwVA8_Pb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}